{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted From:  \n",
    "[Basics of Image Classification with PyTorch - John Olafenwa](https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864)  \n",
    "[SimpleNet.py](https://gist.githubusercontent.com/johnolafenwa/96b3322aabb61d4d36fd870a77f02aa3/raw/997e02bf20b5f7863654d7e863a46a1af67e626e/SimpleNet.py)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip')\n",
    "get_ipython().system('{sys.executable} -m pip install -r requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Unit, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, kernel_size=3, out_channels=out_channels, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        output = self.bn(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleNet, self).__init__()\n",
    "\n",
    "        # Create 14 layers of the unit with max pooling in between\n",
    "        self.unit1 = Unit(in_channels=3, out_channels=32)\n",
    "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
    "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
    "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
    "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
    "\n",
    "        # Add all the units into the Sequential layer in exact order\n",
    "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6,\n",
    "                                 self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
    "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        output = output.view(-1, 128)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the training set, flip the images randomly, crop out and apply mean and std normalization\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Load the training set\n",
    "train_set = CIFAR10(root='./data', train=True, transform=train_transformations, download=True)\n",
    "\n",
    "# Create a loader for the training set\n",
    "dataloader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Define transformations for the test set\n",
    "test_transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "])\n",
    "\n",
    "# Load the test set, note that train is set to False\n",
    "test_set = CIFAR10(root='./data', train=False, transform=test_transformations, download=True)\n",
    "\n",
    "# Create a loader for the test set, note that both shuffle is set to false for the test loader\n",
    "dataloader_test = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Check if gpu support is available\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "print(f'cuda_avail = {cuda_avail}')\n",
    "\n",
    "# Create model, optimizer and loss function\n",
    "model = SimpleNet(num_classes=10)\n",
    "\n",
    "if cuda_avail:\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('WARNING Running on CPU!')\n",
    "    model.cpu()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learning rate adjustment function that divides the learning rate by 10 every 30 epochs\n",
    "def adjust_learning_rate(epoch):\n",
    "    lr = 0.001\n",
    "\n",
    "    if epoch > 180:\n",
    "        lr = lr / 1000000\n",
    "    elif epoch > 150:\n",
    "        lr = lr / 100000\n",
    "    elif epoch > 120:\n",
    "        lr = lr / 10000\n",
    "    elif epoch > 90:\n",
    "        lr = lr / 1000\n",
    "    elif epoch > 60:\n",
    "        lr = lr / 100\n",
    "    elif epoch > 30:\n",
    "        lr = lr / 10\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "def save_models(epoch):\n",
    "    torch.save(model.state_dict(), f'models/cifar10model_{epoch}.model')\n",
    "    print('Checkpoint saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for (images, labels) in dataloader_test:\n",
    "\n",
    "        if cuda_avail:\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        # Predict classes using images from the test set\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        #prediction = prediction.cpu().numpy() -  labels is on gpu, just keep everything there...\n",
    "        test_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "    # Compute the average acc and loss over all test images\n",
    "    test_acc = test_acc / len(dataloader_test.dataset)\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # for epoch in tqdm(range(num_epochs), desc='Epochs'):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(dataloader_train):\n",
    "            # Move images and labels to gpu if available\n",
    "            if cuda_avail:\n",
    "                images = Variable(images.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "\n",
    "            # Clear all accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predict classes using images from the test set\n",
    "            outputs = model(images)\n",
    "            # Compute the loss based on the predictions and actual labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust parameters according to the computed gradients\n",
    "            optimizer.step()\n",
    "           \n",
    "            train_loss += loss.cpu().data.item() * images.size(0)\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "\n",
    "            train_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "        # Call the learning rate adjustment function\n",
    "        adjust_learning_rate(epoch)\n",
    "\n",
    "        # Compute the average acc and loss over all training images\n",
    "        train_acc = train_acc / len(dataloader_train.dataset)\n",
    "        train_loss = train_loss / len(dataloader_train.dataset)\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        test_acc = test()\n",
    "\n",
    "        # Save the model if the test acc is greater than our current best\n",
    "        if test_acc > best_acc:\n",
    "            save_models(epoch)\n",
    "            best_acc = test_acc\n",
    "\n",
    "        # Print the metrics\n",
    "        print(f'Epoch {epoch}, Train Accuracy: {train_acc}, Train Loss: {train_loss}, Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
