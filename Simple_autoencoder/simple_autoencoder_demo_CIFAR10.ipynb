{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted From:  \n",
    "[Building Autoencoder in Pytorch - Vipul Vaibhaw](https://medium.com/@vaibhaw.vipul/building-autoencoder-in-pytorch-34052d1d280c)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip');\n",
    "get_ipython().system('{sys.executable} -m pip install -r ../requirements.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if gpu support is available\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "print(f'cuda_avail = {cuda_avail}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024\n",
    "# im_res=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    # img = img / 2 + 0.5 # unnormalize TODO\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Compute Normalization Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get mean and std deviations per channel for later normalization\n",
    "# do in minibatches, then take the mean over all the minibatches\n",
    "# adapted from: https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n",
    "\n",
    "dl_unnormalized = torch.utils.data.DataLoader(\n",
    "    tv.datasets.ImageFolder(root='C:/imagenet/processed_images/train', transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "pop_mean = []\n",
    "pop_std0 = []\n",
    "# pop_std1 = []\n",
    "for (images, labels) in tqdm(dl_unnormalized, desc='Minibatch'):\n",
    "    # shape = (batch_size, 3, im_res, im_res)\n",
    "    numpy_images = images.numpy()\n",
    "\n",
    "    # shape = (3,)\n",
    "    batch_mean = np.mean(numpy_images, axis=(0,2,3))\n",
    "    batch_std0 = np.std(numpy_images, axis=(0,2,3))\n",
    "    # batch_std1 = np.std(numpy_images, axis=(0,2,3), ddof=1)\n",
    "\n",
    "    pop_mean.append(batch_mean)\n",
    "    pop_std0.append(batch_std0)\n",
    "    # pop_std1.append(batch_std1)\n",
    "\n",
    "# shape = (num_minibatches, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "pop_std0 = np.array(pop_std0).mean(axis=0)\n",
    "# pop_std1 = np.array(pop_std1).mean(axis=0)\n",
    "\n",
    "print(f'pop_mean = {pop_mean}')\n",
    "print(f'pop_std0 = {pop_std0}')\n",
    "# print(f'pop_std1 = {pop_std1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalization results computed earlier\n",
    "pop_mean = np.array([0.48399296, 0.45583892, 0.41094956])\n",
    "pop_std0 = np.array([0.27657014, 0.27107376, 0.28344524])\n",
    "# pop_std1 = np.array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load and manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),  transforms.Normalize(pop_mean, pop_std0)])\n",
    "\n",
    "ds_all_classes = tv.datasets.ImageFolder(root='C:/imagenet/processed_images/train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = OrderedDict({})\n",
    "for k,v in ds_all_classes.class_to_idx.items():\n",
    "    class_to_idx[k.lower()] = v\n",
    "class_to_idx = OrderedDict(sorted(class_to_idx.items(), key=lambda x: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/c/dog-breed-identification/data, plus a few extra\n",
    "possible_dog_classes = ['affenpinscher', 'afghan_hound', 'african_hunting_dog', 'airedale', 'american_staffordshire_terrier', 'appenzeller', 'australian_terrier', 'basenji', 'basset', 'beagle', 'bedlington_terrier', 'bernese_mountain_dog', 'black-and-tan_coonhound', 'blenheim_spaniel', 'bloodhound', 'bluetick', 'border_collie', 'border_terrier', 'borzoi', 'boston_bull', 'bouvier_des_flandres', 'boxer', 'brabancon_griffon', 'briard', 'brittany_spaniel', 'bull_mastiff', 'cairn', 'cardigan', 'chesapeake_bay_retriever', 'chihuahua', 'chow', 'clumber', 'cocker_spaniel', 'collie', 'curly-coated_retriever', 'dandie_dinmont', 'dhole', 'dingo', 'doberman', 'english_foxhound', 'english_setter', 'english_springer', 'entlebucher', 'eskimo_dog', 'flat-coated_retriever', 'french_bulldog', 'german_shepherd', 'german_short-haired_pointer', 'giant_schnauzer', 'golden_retriever', 'gordon_setter', 'great_dane', 'great_pyrenees', 'greater_swiss_mountain_dog', 'groenendael', 'ibizan_hound', 'irish_setter', 'irish_terrier', 'irish_water_spaniel', 'irish_wolfhound', 'italian_greyhound', 'japanese_spaniel', 'keeshond', 'kelpie', 'kerry_blue_terrier', 'komondor', 'kuvasz', 'labrador_retriever', 'lakeland_terrier', 'leonberg', 'lhasa', 'malamute', 'malinois', 'maltese_dog', 'mexican_hairless', 'miniature_pinscher', 'miniature_poodle', 'miniature_schnauzer', 'newfoundland', 'norfolk_terrier', 'norwegian_elkhound', 'norwich_terrier', 'old_english_sheepdog', 'otterhound', 'papillon', 'pekinese', 'pembroke', 'pomeranian', 'pug', 'redbone', 'rhodesian_ridgeback', 'rottweiler', 'saint_bernard', 'saluki', 'samoyed', 'schipperke', 'scotch_terrier', 'scottish_deerhound', 'sealyham_terrier', 'shetland_sheepdog', 'shih-tzu', 'siberian_husky', 'silky_terrier', 'soft-coated_wheaten_terrier', 'staffordshire_bullterrier', 'standard_poodle', 'standard_schnauzer', 'sussex_spaniel', 'tibetan_mastiff', 'tibetan_terrier', 'toy_poodle', 'toy_terrier', 'vizsla', 'walker_hound', 'weimaraner', 'welsh_springer_spaniel', 'west_highland_white_terrier', 'whippet', 'wire-haired_fox_terrier', 'yorkshire_terrier', 'dalmatian', 'coyote', 'timber_wolf', 'white_wolf',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_dog_classes = natsorted(list(set(class_to_idx.keys()).intersection(set(possible_dog_classes))))\n",
    "\n",
    "imagenet_dog_classes_idx = []\n",
    "for c in imagenet_dog_classes:\n",
    "    imagenet_dog_classes_idx.append(class_to_idx[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,class_idx in enumerate(imagenet_dog_classes_idx):\n",
    "    if i == 0:\n",
    "        idx_dogs = torch.tensor(ds_all_classes.targets) == class_idx\n",
    "    else:\n",
    "        idx_dogs += torch.tensor(ds_all_classes.targets) == class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dogs = torch.utils.data.dataset.Subset(ds_all_classes, np.where(idx_dogs==1)[0])\n",
    "\n",
    "del ds_all_classes\n",
    "ds_all_classes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dogs_all = len(ds_dogs.indices)\n",
    "\n",
    "n_dogs_test = int(0.15*n_dogs_all)\n",
    "n_dogs_val = int(0.15*n_dogs_all)\n",
    "n_dogs_train = n_dogs_all - n_dogs_test - n_dogs_val\n",
    "\n",
    "ds_dogs_test, ds_dogs_val, ds_dogs_train = torch.utils.data.random_split(ds_dogs, [n_dogs_test, n_dogs_val, n_dogs_train])\n",
    "\n",
    "del ds_dogs\n",
    "ds_dogs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_dogs_test = torch.utils.data.DataLoader(ds_dogs_test, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "dl_dogs_val = torch.utils.data.DataLoader(ds_dogs_val, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "dl_dogs_train = torch.utils.data.DataLoader(ds_dogs_train, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataiter = iter(dataloader_train_dogs)\n",
    "images, labels = dataiter.next()\n",
    "imshow(images[110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "        self.decoder = nn.Sequential(             \n",
    "            nn.ConvTranspose2d(16, 6, kernel_size=5),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(6, 3, kernel_size=5),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "if cuda_avail:\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('WARNING Running on CPU!')\n",
    "    model.cpu()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-5)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learning rate adjustment function that divides the learning rate by 10 every epoch_period=30 epochs, up to n_period_cap=6 times\n",
    "def adjust_learning_rate(epoch, initial_lr=0.001, epoch_period=30, n_period_cap=6):\n",
    "    exponent = min(n_period_cap, int(np.floor(epoch / epoch_period)))\n",
    "    lr = initial_lr / pow(10, exponent)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "def save_models(epoch):\n",
    "    torch.save(model.state_dict(), f'models/autoencoder_{epoch}.model')\n",
    "    print('Checkpoint saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss():\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    for (images, labels) in dl_dogs_val:\n",
    "        if cuda_avail:\n",
    "            images = Variable(images.cuda())\n",
    "        else:\n",
    "            images = Variable(images.cpu())\n",
    "\n",
    "        # apply model and compute loss using images from the val set\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, images)\n",
    "        val_loss += loss.cpu().data.item() * images.size(0)\n",
    "\n",
    "    # Compute the average loss over all val images\n",
    "    # val_loss = val_loss / len(dl_dogs_val.dataset)\n",
    "    val_loss = val_loss / n_dogs_val\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    best_loss = None\n",
    "\n",
    "    # for epoch in tqdm(range(num_epochs), desc='Epochs'):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        # for (images, labels) in tqdm(dataloader_train, desc='Minibatch'):\n",
    "        for (images, labels) in dl_dogs_train:\n",
    "\n",
    "            # Move images and labels to gpu if available\n",
    "            if cuda_avail:\n",
    "                images = Variable(images.cuda())\n",
    "            else:\n",
    "                images = Variable(images.cpu())\n",
    "\n",
    "            # Clear all accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, images)\n",
    "\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust parameters according to the computed gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # compute loss\n",
    "            train_loss += loss.cpu().data.item() * images.size(0)\n",
    "\n",
    "        # Call the learning rate adjustment function\n",
    "        adjust_learning_rate(epoch)\n",
    "\n",
    "        # Compute the average acc and loss over all training images\n",
    "        # train_loss = train_loss / len(dl_dogs_train.dataset)\n",
    "        train_loss = train_loss / n_dogs_train\n",
    "\n",
    "        # Evaluate on the val set\n",
    "        val_loss = get_val_loss()\n",
    "\n",
    "        # Save the model if the val loss is less than our current best\n",
    "        if epoch == 0 or val_loss < best_loss:\n",
    "            save_models(epoch)\n",
    "            best_loss = val_loss\n",
    "\n",
    "        # Print the metrics\n",
    "        print(f'Epoch {epoch}, Train Loss: {train_loss}, Val Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
