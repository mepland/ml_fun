{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted From:  \n",
    "[Building Autoencoder in Pytorch - Vipul Vaibhaw](https://medium.com/@vaibhaw.vipul/building-autoencoder-in-pytorch-34052d1d280c)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip');\n",
    "get_ipython().system('{sys.executable} -m pip install -r ../requirements.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from natsort import natsorted\n",
    "import humanize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if gpu support is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "im_res=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mem():\n",
    "    cuda_mem_alloc = torch.cuda.memory_allocated() # bytes\n",
    "    print(f'CUDA memory allocated: {humanize.naturalsize(cuda_mem_alloc)}')\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                print(f'type: {type(obj)}, dimensional size: {obj.size()}') # , memory size: {humanize.naturalsize(sys.getsizeof(obj))}') - always 72...\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Compute Normalization Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get mean and std deviations per channel for later normalization\n",
    "# do in minibatches, then take the mean over all the minibatches\n",
    "# adapted from: https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n",
    "\n",
    "dl_unnormalized = torch.utils.data.DataLoader(\n",
    "    tv.datasets.ImageFolder(root='C:/imagenet/processed_images/train', transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "pop_mean = []\n",
    "pop_std0 = []\n",
    "# pop_std1 = []\n",
    "for (images, labels) in tqdm(dl_unnormalized, desc='Minibatch'):\n",
    "    # shape = (batch_size, 3, im_res, im_res)\n",
    "    numpy_images = images.numpy()\n",
    "\n",
    "    # shape = (3,)\n",
    "    batch_mean = np.mean(numpy_images, axis=(0,2,3))\n",
    "    batch_std0 = np.std(numpy_images, axis=(0,2,3))\n",
    "    # batch_std1 = np.std(numpy_images, axis=(0,2,3), ddof=1)\n",
    "\n",
    "    pop_mean.append(batch_mean)\n",
    "    pop_std0.append(batch_std0)\n",
    "    # pop_std1.append(batch_std1)\n",
    "\n",
    "# shape = (num_minibatches, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "pop_std0 = np.array(pop_std0).mean(axis=0)\n",
    "# pop_std1 = np.array(pop_std1).mean(axis=0)\n",
    "\n",
    "print(f'pop_mean = {pop_mean}')\n",
    "print(f'pop_std0 = {pop_std0}')\n",
    "# print(f'pop_std1 = {pop_std1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalization results computed earlier\n",
    "pop_mean = np.array([0.48399296, 0.45583892, 0.41094956])\n",
    "pop_std0 = np.array([0.27657014, 0.27107376, 0.28344524])\n",
    "# pop_std1 = np.array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load and manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),  transforms.Normalize(pop_mean, pop_std0)])\n",
    "\n",
    "ds_all_classes = tv.datasets.ImageFolder(root='C:/imagenet/processed_images/train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = OrderedDict({})\n",
    "for k,v in ds_all_classes.class_to_idx.items():\n",
    "    class_to_idx[k.lower()] = v\n",
    "class_to_idx = OrderedDict(sorted(class_to_idx.items(), key=lambda x: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/c/dog-breed-identification/data, plus a few extra\n",
    "possible_dog_classes = ['affenpinscher', 'afghan_hound', 'african_hunting_dog', 'airedale', 'american_staffordshire_terrier', 'appenzeller', 'australian_terrier', 'basenji', 'basset', 'beagle', 'bedlington_terrier', 'bernese_mountain_dog', 'black-and-tan_coonhound', 'blenheim_spaniel', 'bloodhound', 'bluetick', 'border_collie', 'border_terrier', 'borzoi', 'boston_bull', 'bouvier_des_flandres', 'boxer', 'brabancon_griffon', 'briard', 'brittany_spaniel', 'bull_mastiff', 'cairn', 'cardigan', 'chesapeake_bay_retriever', 'chihuahua', 'chow', 'clumber', 'cocker_spaniel', 'collie', 'curly-coated_retriever', 'dandie_dinmont', 'dhole', 'dingo', 'doberman', 'english_foxhound', 'english_setter', 'english_springer', 'entlebucher', 'eskimo_dog', 'flat-coated_retriever', 'french_bulldog', 'german_shepherd', 'german_short-haired_pointer', 'giant_schnauzer', 'golden_retriever', 'gordon_setter', 'great_dane', 'great_pyrenees', 'greater_swiss_mountain_dog', 'groenendael', 'ibizan_hound', 'irish_setter', 'irish_terrier', 'irish_water_spaniel', 'irish_wolfhound', 'italian_greyhound', 'japanese_spaniel', 'keeshond', 'kelpie', 'kerry_blue_terrier', 'komondor', 'kuvasz', 'labrador_retriever', 'lakeland_terrier', 'leonberg', 'lhasa', 'malamute', 'malinois', 'maltese_dog', 'mexican_hairless', 'miniature_pinscher', 'miniature_poodle', 'miniature_schnauzer', 'newfoundland', 'norfolk_terrier', 'norwegian_elkhound', 'norwich_terrier', 'old_english_sheepdog', 'otterhound', 'papillon', 'pekinese', 'pembroke', 'pomeranian', 'pug', 'redbone', 'rhodesian_ridgeback', 'rottweiler', 'saint_bernard', 'saluki', 'samoyed', 'schipperke', 'scotch_terrier', 'scottish_deerhound', 'sealyham_terrier', 'shetland_sheepdog', 'shih-tzu', 'siberian_husky', 'silky_terrier', 'soft-coated_wheaten_terrier', 'staffordshire_bullterrier', 'standard_poodle', 'standard_schnauzer', 'sussex_spaniel', 'tibetan_mastiff', 'tibetan_terrier', 'toy_poodle', 'toy_terrier', 'vizsla', 'walker_hound', 'weimaraner', 'welsh_springer_spaniel', 'west_highland_white_terrier', 'whippet', 'wire-haired_fox_terrier', 'yorkshire_terrier', 'dalmatian', 'coyote', 'timber_wolf', 'white_wolf',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_dog_classes = natsorted(list(set(class_to_idx.keys()).intersection(set(possible_dog_classes))))\n",
    "\n",
    "imagenet_dog_classes_idx = []\n",
    "for c in imagenet_dog_classes:\n",
    "    imagenet_dog_classes_idx.append(class_to_idx[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,class_idx in enumerate(imagenet_dog_classes_idx):\n",
    "    if i == 0:\n",
    "        idx_dogs = torch.tensor(ds_all_classes.targets) == class_idx\n",
    "    else:\n",
    "        idx_dogs += torch.tensor(ds_all_classes.targets) == class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dogs = torch.utils.data.dataset.Subset(ds_all_classes, np.where(idx_dogs==1)[0])\n",
    "\n",
    "# del idx_dogs\n",
    "# idx_dogs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dogs_all = len(ds_dogs.indices)\n",
    "\n",
    "n_dogs_test = int(0.15*n_dogs_all)\n",
    "n_dogs_val = int(0.15*n_dogs_all)\n",
    "n_dogs_train = n_dogs_all - n_dogs_test - n_dogs_val\n",
    "\n",
    "ds_dogs_test, ds_dogs_val, ds_dogs_train = torch.utils.data.random_split(ds_dogs, [n_dogs_test, n_dogs_val, n_dogs_train])\n",
    "\n",
    "del ds_dogs\n",
    "ds_dogs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_dogs_test = torch.utils.data.DataLoader(ds_dogs_test, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "dl_dogs_val = torch.utils.data.DataLoader(ds_dogs_val, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "dl_dogs_train = torch.utils.data.DataLoader(ds_dogs_train, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Decoder\n",
    "        self.conv5 = nn.ConvTranspose2d(16, 64, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.conv6 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.conv7 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn7 = nn.BatchNorm2d(16)\n",
    "        self.conv8 = nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def encode(self, x):\n",
    "        conv1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        conv2 = self.relu(self.bn2(self.conv2(conv1)))\n",
    "        conv3 = self.relu(self.bn3(self.conv3(conv2)))\n",
    "        conv4 = self.relu(self.bn4(self.conv4(conv3)))\n",
    "\n",
    "        return conv4\n",
    "\n",
    "    def decode(self, z):\n",
    "        conv5 = self.relu(self.bn5(self.conv5(z)))\n",
    "        conv6 = self.relu(self.bn6(self.conv6(conv5)))\n",
    "        conv7 = self.relu(self.bn7(self.conv7(conv6)))\n",
    "\n",
    "        return self.conv8(conv7).view(-1, 3, im_res, im_res)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-5)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learning rate adjustment function that divides the learning rate by 10 every epoch_period=30 epochs, up to n_period_cap=6 times\n",
    "def adjust_learning_rate(epoch, initial_lr=0.001, epoch_period=30, n_period_cap=6):\n",
    "    exponent = min(n_period_cap, int(np.floor(epoch / epoch_period)))\n",
    "    lr = initial_lr / pow(10, exponent)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "def save_model(epoch, model_name='autoencoder'):\n",
    "    torch.save(model.state_dict(), f'models/{model_name}_{epoch}.model')\n",
    "    print('Checkpoint saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(epoch, model_name='autoencoder'):\n",
    "    model = Autoencoder()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(f'models/{model_name}_{epoch}.model'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss():\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    for (images, labels) in dl_dogs_val:\n",
    "        images = images.to(device)\n",
    "\n",
    "        # apply model and compute loss using images from the val set\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, images)\n",
    "        val_loss += loss.cpu().data.item() * images.size(0)\n",
    "\n",
    "    # Compute the average loss over all val images\n",
    "    # val_loss = val_loss / len(dl_dogs_val.dataset)\n",
    "    val_loss = val_loss / n_dogs_val\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    best_loss = None\n",
    "\n",
    "    # for epoch in tqdm(range(num_epochs), desc='Epochs'):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        # for (images, labels) in tqdm(dataloader_train, desc='Minibatch'):\n",
    "        for (images, labels) in dl_dogs_train:\n",
    "\n",
    "            # Move images and labels to gpu if available\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Clear all accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, images)\n",
    "\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust parameters according to the computed gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # compute loss\n",
    "            train_loss += loss.cpu().data.item() * images.size(0)\n",
    "\n",
    "        # Call the learning rate adjustment function\n",
    "        adjust_learning_rate(epoch)\n",
    "\n",
    "        # Compute the average acc and loss over all training images\n",
    "        # train_loss = train_loss / len(dl_dogs_train.dataset)\n",
    "        train_loss = train_loss / n_dogs_train\n",
    "\n",
    "        # Evaluate on the val set\n",
    "        val_loss = get_val_loss()\n",
    "\n",
    "        # Save the model if the val loss is less than our current best\n",
    "        if epoch == 0 or val_loss < best_loss:\n",
    "            save_model(epoch)\n",
    "            best_loss = val_loss\n",
    "\n",
    "        # Print the metrics\n",
    "        print(f'Epoch {epoch}, Train Loss: {train_loss}, Val Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(im, mean=pop_mean, std=pop_std0):\n",
    "    if isinstance(im, torch.Tensor):\n",
    "        im = im.numpy()\n",
    "    # unnormalize\n",
    "    if std is not None and mean is not None:\n",
    "        im_unnorm = np.zeros(im.shape)\n",
    "        for channel in range(im.shape[0]):\n",
    "            im_unnorm[channel] = std[channel]*im[channel] + mean[channel]\n",
    "        im = im_unnorm\n",
    "        del im_unnorm\n",
    "\n",
    "    # transpose from (channels, im_res, im_res) to (im_res, im_res, channels) for imshow plotting\n",
    "    im = np.transpose(im, (1, 2, 0))\n",
    "    \n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = iter(dl_dogs_val).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(91)\n",
    "# model = load_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(images.to(device))\n",
    "outputs_cpu = outputs.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(outputs_cpu[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_NOT_dogs = torch.utils.data.dataset.Subset(ds_all_classes, np.where(idx_dogs!=1)[0])\n",
    "dl_NOT_dogs = torch.utils.data.DataLoader(ds_NOT_dogs, batch_size=100, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = iter(dl_NOT_dogs).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(images.to(device))\n",
    "outputs_cpu = outputs.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(outputs_cpu[10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
