{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted From:  \n",
    "[Building Autoencoder in Pytorch - Vipul Vaibhaw](https://medium.com/@vaibhaw.vipul/building-autoencoder-in-pytorch-34052d1d280c)  \n",
    "[Variational AutoEncoders for new fruits with Keras and Pytorch - Thomas Dehaene](https://becominghuman.ai/variational-autoencoders-for-new-fruits-with-keras-and-pytorch-6d0cfc4eeabd)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip');\n",
    "get_ipython().system('{sys.executable} -m pip install -r ../requirements.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('~/ml_fun/'))\n",
    "from common_code import *\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if gpu support is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "im_res=128\n",
    "latent_dim = 7 # Latent Space size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Compressing from {im_res} x {im_res} to a latent dimension of {latent_dim} x {latent_dim}, ie shinking to {latent_dim}^2/{im_res}^2 = {latent_dim**2 / im_res**2:.2%} of the original size, before expanding back to {im_res} x {im_res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential good \"nominal\" classes\n",
    "nominal_classes = ['manhole_cover', 'car_wheel', 'barometer', 'bottlecap', 'lens_cap', 'puck', 'analog_clock', 'wall_clock', 'coffee_mug', 'coffeepot']\n",
    "nominal_class = nominal_classes[0]\n",
    "print(f'Running with nominal class: {nominal_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../output/{nominal_class}_latent_dim_{latent_dim}'\n",
    "models_path = f'../models/{nominal_class}_latent_dim_{latent_dim}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Compute Normalization Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl_unnormalized = torch.utils.data.DataLoader(\n",
    "    tv.datasets.ImageFolder(root='C:/imagenet/processed_images/train', transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "pop_mean, pop_std0 = compute_channel_norms(dl_unnormalized)\n",
    "\n",
    "print(f'pop_mean = {pop_mean}')\n",
    "print(f'pop_std0 = {pop_std0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalization results computed earlier\n",
    "pop_mean = np.array([0.48399296, 0.45583892, 0.41094956])\n",
    "pop_std0 = np.array([0.27657014, 0.27107376, 0.28344524])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load and manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(pop_mean, pop_std0)])\n",
    "\n",
    "ds_all_classes = tv.datasets.ImageFolder(root='C:/imagenet/processed_images/train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = OrderedDict({})\n",
    "for k,v in ds_all_classes.class_to_idx.items():\n",
    "    class_to_idx[k.lower()] = v\n",
    "class_to_idx = OrderedDict(sorted(class_to_idx.items(), key=lambda x: x))\n",
    "idx_to_class = OrderedDict([[v,k] for k,v in class_to_idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_nominal = class_to_idx[nominal_class]\n",
    "idx_nominal_tensor = torch.tensor(ds_all_classes.targets) == idx_nominal\n",
    "ds_nominal = torch.utils.data.dataset.Subset(ds_all_classes, np.where(idx_nominal_tensor==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nominal_all = len(ds_nominal.indices)\n",
    "\n",
    "n_nominal_test = int(0.15*n_nominal_all)\n",
    "n_nominal_val = int(0.15*n_nominal_all)\n",
    "n_nominal_train = n_nominal_all - n_nominal_test - n_nominal_val\n",
    "\n",
    "ds_nominal_test, ds_nominal_val, ds_nominal_train = torch.utils.data.random_split(ds_nominal, [n_nominal_test, n_nominal_val, n_nominal_train])\n",
    "\n",
    "del ds_nominal; ds_nominal = None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_nominal_test = torch.utils.data.DataLoader(ds_nominal_test, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "dl_nominal_val = torch.utils.data.DataLoader(ds_nominal_val, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "dl_nominal_train = torch.utils.data.DataLoader(ds_nominal_train, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Latent Space size, latent_dim, defined earlier\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, latent_dim, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.conv5 = nn.ConvTranspose2d(latent_dim, 64, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.conv6 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.conv7 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn7 = nn.BatchNorm2d(16)\n",
    "        self.conv8 = nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def encode(self, x):\n",
    "        conv1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        conv2 = self.relu(self.bn2(self.conv2(conv1)))\n",
    "        conv3 = self.relu(self.bn3(self.conv3(conv2)))\n",
    "        conv4 = self.relu(self.bn4(self.conv4(conv3)))\n",
    "\n",
    "        return conv4\n",
    "\n",
    "    def decode(self, z):\n",
    "        conv5 = self.relu(self.bn5(self.conv5(z)))\n",
    "        conv6 = self.relu(self.bn6(self.conv6(conv5)))\n",
    "        conv7 = self.relu(self.bn7(self.conv7(conv6)))\n",
    "\n",
    "        return self.conv8(conv7).view(-1, 3, im_res, im_res)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "loss_fn_no_reduction = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = train_model(dl_nominal_train, dl_nominal_val,\n",
    "model, optimizer, loss_fn, device,\n",
    "model_name='autoencoder', models_path=models_path,\n",
    "max_epochs=100, do_es=True, es_min_val_per_improvement=0.01, es_epochs=5,\n",
    "do_decay_lr=True, initial_lr=0.001, lr_epoch_period=30, lr_n_period_cap=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dfp(dfp_train_results, output_path , 'train_results', tag='',\n",
    "          target_fixed_cols=['epoch', 'train_loss', 'val_loss', 'best_val_loss', 'delta_per_best', 'saved_model', 'cuda_mem_alloc'],\n",
    "          sort_by=['epoch'], sort_by_ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = load_dfp(output_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                             cols_float=['train_loss','val_loss','best_val_loss','delta_per_best'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfp_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': True},\n",
    "                   loss_cols=['train_loss', 'val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 40\n",
    "model = Autoencoder()\n",
    "load_model(model, device, best_epoch, 'autoencoder', models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(dl, model, loss_fn, loss_fn_no_reduction, device, m_path, fname='im_comp', tag='',\n",
    "               print_plots=True, n_comps_to_print=20, loss_type='\\nLoss is MSE',\n",
    "               return_loss_stats=True, dl_name=None,\n",
    "               idx_to_class=idx_to_class, mean_unnormalize=pop_mean, std_unnormalize=pop_std0):\n",
    "    if not isinstance(loss_fn, nn.modules.loss.MSELoss):\n",
    "        raise ValueError('Expected loss_fn == nn.MSELoss(), as individual loss annotation on numpy objects uses MSE. Update code and rerun!')\n",
    "\n",
    "    class_arrays = []\n",
    "    loss_arrays = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if print_plots:\n",
    "            eval_loss = get_loss(dl, model, loss_fn, device)\n",
    "\n",
    "        i_comps = 0\n",
    "        for (images, classes) in tqdm(dl, desc='Minibatch'):\n",
    "            # move labels to cpu\n",
    "            classes_np = classes.numpy()\n",
    "            class_arrays.append(classes_np)\n",
    "\n",
    "            # move data to device\n",
    "            images = images.to(device)\n",
    "\n",
    "            # evaluate with model\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss_per_pixel = loss_fn_no_reduction(outputs, images).cpu().numpy()\n",
    "            loss_per_image = np.reshape(loss_per_pixel, (loss_per_pixel.shape[0], -1)).mean(axis=1)\n",
    "            loss_arrays.append(loss_per_image)\n",
    "\n",
    "            if print_plots:\n",
    "                def _helper_plot_im_comp(i, _m_path, _fname, _tag='', _ann_add=''):\n",
    "                    class_name = idx_to_class[classes_np[i]]\n",
    "\n",
    "                    im_orig = images[i].cpu().numpy()\n",
    "                    im_pred = outputs[i].cpu().numpy()\n",
    "\n",
    "                    # compute MSE loss in numpy\n",
    "                    # this_loss = np.square(np.subtract(im_orig, im_pred)).mean()\n",
    "\n",
    "                    # get from earlier calculation\n",
    "                    this_loss = loss_per_image[i]\n",
    "\n",
    "                    _tag = f'{_tag}_{class_name}{tag}'\n",
    "\n",
    "                    plot_im_comp(im_orig, im_pred, _m_path, _fname, tag=_tag, inline=False,\n",
    "                                 ann_text_std_add=f'Loss: {this_loss:.04f}\\nMean Loss: {eval_loss:.04f}{loss_type}\\n{class_name.title()}{_ann_add}',\n",
    "                                 mean_unnormalize=mean_unnormalize, std_unnormalize=std_unnormalize,\n",
    "                                 ann_margin=True, left_right_orig_pred=True,\n",
    "                                )\n",
    "\n",
    "                # plot image comparisions, up to n_comps\n",
    "                i = 0\n",
    "                n_outputs = len(outputs)\n",
    "                while i < n_outputs and i_comps < n_comps_to_print:\n",
    "                    _helper_plot_im_comp(i, m_path, fname, _tag=f'_{i_comps}', _ann_add='')\n",
    "                    i += 1; i_comps += 1;\n",
    "\n",
    "                # plot image comparisions for max / min loss in this batch\n",
    "                i_min = loss_per_image.argmin()\n",
    "                l_min = loss_per_image[i_min]\n",
    "                _helper_plot_im_comp(i_min, f'{m_path}/mins', f'min_{l_min:.6f}_fname'.replace('.', '_'), _ann_add=f'\\nMin Loss')\n",
    "\n",
    "                i_max = loss_per_image.argmax()\n",
    "                l_max = loss_per_image[i_max]\n",
    "                _helper_plot_im_comp(i_max, f'{m_path}/maxs', f'max_{l_max:.6f}_fname'.replace('.', '_'), _ann_add=f'\\nMax Loss')\n",
    "\n",
    "        if return_loss_stats:\n",
    "            loss_array = np.concatenate(loss_arrays).ravel()\n",
    "            class_array = np.concatenate(class_arrays).ravel()\n",
    "            idxs = natsorted(list(set(class_array)))\n",
    "\n",
    "            def _get_l_stats(la, name=None):\n",
    "                return {\n",
    "                        'name': name, 'l_mean': la.mean(), 'l_stddev': la.std(), 'l_min': la.min(), 'l_max': la.max(),\n",
    "                        'l_median': np.median(la), 'n_images': la.size\n",
    "                       }\n",
    "\n",
    "            results = []\n",
    "            for idx in tqdm(idxs, desc='Class'):\n",
    "                this_loss_array = loss_array[np.where(class_array==idx)]\n",
    "                results.append(_get_l_stats(this_loss_array, name=idx_to_class[idx]))\n",
    "\n",
    "            if dl_name is not None:\n",
    "                results.append(_get_l_stats(loss_array, name=dl_name))\n",
    "\n",
    "            return pd.DataFrame(results)[['name', 'l_mean', 'l_stddev', 'l_min', 'l_max', 'l_median', 'n_images']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Stats on Nominal Class\n",
    "Also plot some original / reconstructed image comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal\n",
    "dfp_nominal = eval_model(dl_nominal_val, model, loss_fn, loss_fn_no_reduction, device, f'{output_path}/comps/nominal')\n",
    "dfp_nominal['nominal'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Stats on NOT Nominal Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not nominal\n",
    "ds_NOT_nominal = torch.utils.data.dataset.Subset(ds_all_classes, np.where(idx_nominal_tensor!=1)[0])\n",
    "dl_NOT_nominal = torch.utils.data.DataLoader(ds_NOT_nominal, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all not nominal class stats, but don't plot\n",
    "dfp_NOT_nominal = eval_model(dl_NOT_nominal, model, loss_fn, loss_fn_no_reduction, device, None, print_plots=False, dl_name='not_nominal')\n",
    "dfp_NOT_nominal['nominal'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_class_results = pd.concat([dfp_nominal, dfp_NOT_nominal])\n",
    "dfp_class_results = massage_dfp(dfp_class_results, target_fixed_cols=['nominal', 'name', 'l_mean', 'l_stddev', 'l_min', 'l_max', 'l_median', 'n_images'],\n",
    "                                sort_by=['nominal', 'l_median'], sort_by_ascending=[False, True])\n",
    "write_dfp(dfp_class_results, output_path, 'class_results', tag='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_class_results.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_class_results.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Image Comparisons for Select NOT Nominal Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# interesting_NOT_nominals = ['analog_clock', 'samoyed', 'scuba_diver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(interesting_NOT_nominals)\n",
    "for _class in pbar:\n",
    "    pbar.set_description(f'Processing {_class}')\n",
    "\n",
    "    idx = class_to_idx[_class]\n",
    "    this_idx = torch.tensor(ds_all_classes.targets) == idx\n",
    "    ds = torch.utils.data.dataset.Subset(ds_all_classes, np.where(this_idx==1)[0])\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    eval_model(dl, model, loss_fn, loss_fn_no_reduction, device, f'{output_path}/comps/{_class}', return_loss_stats=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
